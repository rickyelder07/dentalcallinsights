You are an expert full-stack engineer and will act as my Cursor copilot. Project: "DentalCallInsights" — a Next.js + Supabase web app for turning call MP3s + call metadata into searchable transcripts, summaries, sentiment, and actionable insights. I need you to implement Milestone 5: AI Insights with GPT-4o integration focused on four core features: Sentiment Analysis, Call Summary, Action Items, and Red Flags/Concerns.

🎯 Project Context
Current Status: ✅ Milestones 1-4 Complete (Authentication, User Management, Audio Upload & Storage, Transcription Pipeline with Language Detection)
Target: 🚧 Milestone 5 - AI Insights (Simplified)
Branch: milestone/05-ai-insights
Problem: Dental office managers have transcribed call recordings but need quick AI-powered insights to understand call quality, identify required follow-ups, and flag potential issues without reading entire transcripts.
Core User Action: View call → Auto-generate 4 key insights → Review summary, sentiment, actions, and concerns → Take appropriate action.
Aha Moment: Managers can instantly understand call quality and required actions in 10 seconds instead of 5 minutes of reading/listening.

📋 Requirements & Constraints
Tech Stack: Next.js 14 (App Router), TypeScript, TailwindCSS, Supabase (Auth, Postgres, Storage), OpenAI GPT-4o, Vercel
Code Style: TypeScript strict mode, ESLint, Prettier, functional React components with hooks
Security: RLS policies for user data isolation, API key protection (server-side only), input validation
Performance: Background processing for insights, caching to reduce API costs, streaming responses (optional)
Cost Management: Basic token tracking, caching layer to prevent redundant API calls
Integration: Build on existing transcription system (Milestone 4), simple and focused implementation

🎯 Core Features (4 Only)

1. **Call Summary**
   - Concise 2-3 sentence summary of the entire call
   - 3-5 key discussion points as bullet list
   - Call outcome (Resolved, Pending Follow-up, Escalated, No Resolution)
   - Clear, actionable language for quick understanding

2. **Sentiment Analysis**
   - Overall call sentiment: Positive, Neutral, Negative, Mixed
   - Patient satisfaction indicator (Happy, Satisfied, Neutral, Frustrated, Angry)
   - Staff performance indicator (Professional, Needs Improvement)
   - Simple visual display with color coding and emojis

3. **Action Items**
   - Specific follow-up actions required (3-5 items max)
   - Priority: Urgent, High, Normal, Low
   - Assignee: Staff, Patient, Dentist, Billing, Front Desk
   - Simple checklist format

4. **Red Flags & Concerns**
   - Potential compliance issues (HIPAA, unprofessional language)
   - Patient dissatisfaction indicators
   - Missed appointment opportunities
   - Billing/insurance concerns
   - Emergency situations
   - Only show if issues are detected (empty state if none)

🎯 Deliverables (create real files; show file path + file content)

1. OpenAI GPT-4o Integration
lib/openai-insights.ts - GPT-4o API client for insights generation
lib/prompt-templates.ts - Optimized prompts for the 4 core insights
lib/insights-cache.ts - Simple caching layer to prevent redundant API calls
Error handling and retry logic

2. Insights Generation API
app/api/insights/generate/route.ts - Generate insights for a single call
app/api/insights/regenerate/route.ts - Regenerate insights with fresh data
Automatic generation on first view of call detail page
Manual regenerate button for users

3. Insights Display Components
app/components/InsightsSummary.tsx - Summary card with key points
app/components/SentimentIndicator.tsx - Visual sentiment display with colors/emojis
app/components/ActionItemsList.tsx - Checklist of action items
app/components/RedFlagsList.tsx - List of concerns/red flags (conditional display)
app/components/InsightsPanel.tsx - Unified container for all 4 insights

4. Database Schema Updates
migrations/006_insights_schema.sql - Simple insights table with RLS
Store: summary, sentiment, action items, red flags
Track: model used, generated timestamp
No complex cost tracking or jobs tables (keep it simple)

5. Enhanced Call Detail Page
app/calls/[id]/page.tsx - Update with insights panel
Auto-generate insights on first view
Loading state with skeleton
Manual "Regenerate Insights" button
Export insights button (simple JSON/text export)

6. TypeScript Types
types/insights.ts - Core insight types (summary, sentiment, actions, red flags)
Simple, focused type definitions

🔧 Technical Specifications

Call Length Validation
Minimum call duration: 6 seconds
Calls shorter than 6 seconds: Return "Too short for insights" for all fields
Reason: Very short calls typically contain no meaningful content and waste API costs
Implementation: Check call_duration_seconds before API call

OpenAI GPT-4o Configuration
Model: gpt-4o (latest stable)
Max tokens: 800 output tokens (sufficient for 4 insights)
Temperature: 0.3 (consistent, deterministic results)
Response format: JSON for structured output
Function calling: Use for predictable structure
Context window: 128K tokens (handles longest calls)

Prompt Strategy
Single prompt that generates all 4 insights in one API call
JSON output with clear structure:

For calls ≥ 6 seconds:
{
  "summary": {
    "brief": "2-3 sentences",
    "key_points": ["point 1", "point 2", "point 3"],
    "outcome": "Resolved" | "Pending" | "Escalated" | "No Resolution"
  },
  "sentiment": {
    "overall": "positive" | "neutral" | "negative" | "mixed",
    "patient_satisfaction": "happy" | "satisfied" | "neutral" | "frustrated" | "angry",
    "staff_performance": "professional" | "needs_improvement"
  },
  "action_items": [
    {
      "action": "Description",
      "priority": "urgent" | "high" | "normal" | "low",
      "assignee": "staff" | "patient" | "dentist" | "billing" | "front_desk"
    }
  ],
  "red_flags": [
    {
      "concern": "Description",
      "severity": "high" | "medium" | "low",
      "category": "compliance" | "dissatisfaction" | "missed_opportunity" | "billing" | "emergency"
    }
  ]
}

For calls < 6 seconds:
{
  "summary": {
    "brief": "Too short for insights",
    "key_points": ["Too short for insights"],
    "outcome": "Too short for insights"
  },
  "sentiment": {
    "overall": "Too short for insights",
    "patient_satisfaction": "Too short for insights",
    "staff_performance": "Too short for insights"
  },
  "action_items": [],
  "red_flags": []
}

Caching Strategy
Cache insights for 30 days
Cache key: call_id + transcript hash
Regenerate only on explicit user request or transcript change
Simple in-database caching (no Redis needed)

Call Length Validation
Before making API call, check call_duration_seconds:
- If ≥ 6 seconds: Proceed with GPT-4o API call
- If < 6 seconds: Return "Too short for insights" for all fields
- If duration is null/undefined: Default to "Too short for insights"
- Save to database with same structure as API response

🗄️ Database Schema Updates (Simplified)

Insights Table:
```sql
CREATE TABLE IF NOT EXISTS insights (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    call_id UUID NOT NULL REFERENCES calls(id) ON DELETE CASCADE,
    user_id UUID NOT NULL,
    
    -- Summary
    summary_brief TEXT NOT NULL,
    summary_key_points TEXT[] NOT NULL, -- Array of strings
    call_outcome TEXT, -- 'resolved', 'pending', 'escalated', 'no_resolution'
    
    -- Sentiment
    overall_sentiment TEXT NOT NULL, -- 'positive', 'negative', 'neutral', 'mixed'
    patient_satisfaction TEXT, -- 'happy', 'satisfied', 'neutral', 'frustrated', 'angry'
    staff_performance TEXT, -- 'professional', 'needs_improvement'
    
    -- Action Items (stored as JSONB)
    action_items JSONB NOT NULL DEFAULT '[]',
    
    -- Red Flags (stored as JSONB)
    red_flags JSONB NOT NULL DEFAULT '[]',
    
    -- Metadata
    model_used TEXT DEFAULT 'gpt-4o',
    transcript_hash TEXT, -- For cache invalidation
    generated_at TIMESTAMPTZ DEFAULT NOW(),
    
    -- Timestamps
    created_at TIMESTAMPTZ DEFAULT NOW(),
    updated_at TIMESTAMPTZ DEFAULT NOW(),
    
    -- Unique constraint for caching
    UNIQUE(call_id)
);

-- Indexes
CREATE INDEX idx_insights_call_id ON insights(call_id);
CREATE INDEX idx_insights_user_id ON insights(user_id);
CREATE INDEX idx_insights_sentiment ON insights(overall_sentiment);
CREATE INDEX idx_insights_generated_at ON insights(generated_at);
CREATE INDEX idx_insights_transcript_hash ON insights(transcript_hash);

-- RLS Policies
ALTER TABLE insights ENABLE ROW LEVEL SECURITY;

CREATE POLICY "Users can view own insights" ON insights
FOR SELECT USING (user_id = auth.uid());

CREATE POLICY "Users can insert own insights" ON insights
FOR INSERT WITH CHECK (user_id = auth.uid());

CREATE POLICY "Users can update own insights" ON insights
FOR UPDATE USING (user_id = auth.uid());

CREATE POLICY "Users can delete own insights" ON insights
FOR DELETE USING (user_id = auth.uid());
```

That's it! No complex jobs table, cost tracking, or feedback tables. Keep it simple.

🎨 UI/UX Requirements

Call Detail Page Integration:
- Add "Insights" tab next to "Transcript" tab
- Auto-generate insights when user first views the call
- Show loading skeleton while generating
- Display all 4 insights in clean, scannable layout
- "Regenerate Insights" button at top (icon + text)
- Export button (download as JSON or formatted text)

Summary Card:
- 2-3 sentence summary in larger text
- Key points as bulleted list (3-5 items)
- Call outcome badge (color-coded: green=resolved, yellow=pending, red=escalated)
- Clean typography with good spacing

Sentiment Indicator:
- Large emoji/icon for overall sentiment
  - Positive: 😊 Green
  - Neutral: 😐 Gray
  - Negative: 😟 Red
  - Mixed: 🤔 Orange
- Patient satisfaction: Sub-indicator with smaller emoji/text
- Staff performance: Simple badge ("Professional" green, "Needs Improvement" yellow)
- Clean visual hierarchy

Action Items List:
- Checkbox list format (non-functional checkboxes for now)
- Priority indicator: Color-coded dot or badge
  - Urgent: Red
  - High: Orange
  - Normal: Blue
  - Low: Gray
- Assignee badge next to each item
- Maximum 5 items displayed
- If no actions: "No action items identified"

Red Flags List:
- Only show section if red flags exist
- List format with severity indicator
- Color-coded by severity:
  - High: Red with warning icon
  - Medium: Orange
  - Low: Yellow
- Category badge (compliance, dissatisfaction, etc.)
- If no red flags: Hide section entirely or show green checkmark "No concerns identified"

Insights Panel Layout:
```
┌─────────────────────────────────────────────┐
│ 🔄 Regenerate Insights    📥 Export         │
├─────────────────────────────────────────────┤
│                                             │
│ 📝 Summary                                  │
│ [2-3 sentence summary text]                │
│ • Key point 1                               │
│ • Key point 2                               │
│ • Key point 3                               │
│ Outcome: [Resolved badge]                   │
│                                             │
├─────────────────────────────────────────────┤
│                                             │
│ 💭 Sentiment                                │
│ Overall: 😊 Positive                        │
│ Patient: Happy                              │
│ Staff: Professional                         │
│                                             │
├─────────────────────────────────────────────┤
│                                             │
│ ✅ Action Items                             │
│ ☐ [High] Follow up with patient - Staff    │
│ ☐ [Normal] Update billing - Billing        │
│ ☐ [Low] Send confirmation - Front Desk     │
│                                             │
├─────────────────────────────────────────────┤
│                                             │
│ ⚠️ Red Flags & Concerns                     │
│ • [High] Potential HIPAA concern detected   │
│ • [Medium] Patient expressed frustration    │
│                                             │
└─────────────────────────────────────────────┘
```

Loading State:
- Skeleton loaders for each section
- "Generating insights..." message
- Animated spinner or progress indicator
- Estimated time: "Usually takes 5-10 seconds"

Error State:
- Clear error message
- "Retry" button
- Fallback: "Unable to generate insights. Please try again."

📊 Success Metrics

Functional Requirements:
✅ Insights automatically generate when user views a call for the first time
✅ All 4 core insights display correctly (summary, sentiment, actions, red flags)
✅ Regenerate button works and updates insights
✅ Caching prevents redundant API calls for same transcript
✅ Export functionality works (JSON/text download)
✅ RLS policies prevent cross-user access

Performance Requirements:
✅ Insights generation completes within 10 seconds
✅ Cached insights load instantly (< 1 second)
✅ No blocking UI during generation (loading state)
✅ Page remains responsive during processing

Quality Requirements:
✅ Summaries are concise and accurate
✅ Sentiment reflects actual call tone
✅ Action items are specific and actionable
✅ Red flags accurately identify concerns
✅ Empty states handled gracefully (no action items, no red flags)

Security Requirements:
✅ API keys never exposed to client
✅ RLS policies enforce user isolation
✅ Input validation on all API endpoints
✅ Transcript content sanitized before sending to OpenAI

🚀 Implementation Phases

Phase 1: GPT-4o Integration (Week 1)
- Set up OpenAI API client
- Design prompt template for 4 insights
- Test prompt with sample transcripts
- Implement JSON response parsing
- Add error handling and retries
- Test with various call types

Phase 2: Database & API (Week 1-2)
- Create insights table with RLS
- Create /api/insights/generate endpoint
- Create /api/insights/regenerate endpoint
- Implement caching logic (transcript hash)
- Test database operations
- Test API security

Phase 3: UI Components (Week 2)
- Create InsightsSummary component
- Create SentimentIndicator component
- Create ActionItemsList component
- Create RedFlagsList component
- Create InsightsPanel container
- Test components with mock data

Phase 4: Integration (Week 2-3)
- Update call detail page with insights tab
- Implement auto-generation on first view
- Add regenerate button functionality
- Add export functionality
- Test end-to-end workflow
- Handle loading and error states

Phase 5: Polish & Testing (Week 3)
- Refine UI styling and spacing
- Optimize prompt for better quality
- Test with real call data
- Fix edge cases
- Update documentation
- Final testing

📁 File Structure (Simplified)

app/
├── calls/
│   └── [id]/
│       └── page.tsx                    # Updated with insights tab
├── api/
│   └── insights/
│       ├── generate/
│       │   └── route.ts               # Generate insights
│       └── regenerate/
│           └── route.ts               # Regenerate insights
├── components/
│   ├── InsightsSummary.tsx            # Summary card
│   ├── SentimentIndicator.tsx         # Sentiment display
│   ├── ActionItemsList.tsx            # Action items
│   ├── RedFlagsList.tsx               # Red flags
│   └── InsightsPanel.tsx              # Container

lib/
├── openai-insights.ts                 # GPT-4o client
├── prompt-templates.ts                # Prompts for insights
└── insights-cache.ts                  # Caching utilities

types/
└── insights.ts                        # TypeScript types

migrations/
└── 006_insights_schema.sql            # Database schema

🔒 Security Considerations

API Key Protection:
- Server-side only: OpenAI API key never exposed to client
- Environment variable: OPENAI_API_KEY in .env.local
- Error messages: Never include API key in error responses

Data Protection:
- User Isolation: RLS policies ensure users only see their own insights
- Input Validation: Validate call_id exists and belongs to user
- Access Control: Authenticated users only
- Sanitization: Clean transcript content before sending to API

Rate Limiting:
- Per-user rate limiting to prevent abuse
- Max 10 insights generations per minute per user
- Cached insights don't count toward limit

🧪 Testing Strategy

Unit Tests:
- OpenAI API client functions
- Prompt template rendering
- JSON response parsing
- Caching logic (hash generation, cache hit/miss)

Integration Tests:
- End-to-end insights generation
- Database operations with RLS
- API endpoint security
- Error handling and retries
- Cache invalidation on transcript change

Manual Testing:
- Generate insights for various call types
- Verify all 4 insights are accurate and relevant
- Test regenerate functionality
- Test with long transcripts (token limits)
- Test with poor quality transcripts
- Verify caching works correctly
- Test error states and recovery

📚 Documentation Updates

Update existing documentation:
- README.md - Add AI insights features
- CODEFLOW.md - Update Milestone 5 status
- PROJECT_STRUCTURE.md - Add new files

Create new documentation:
- AI_INSIGHTS_SETUP.md - Setup guide for GPT-4o integration
- INSIGHTS_GUIDE.md - How to use insights features

🎯 Success Criteria

Done looks like:
✅ User views a call and sees "Generate Insights" or auto-generated insights
✅ Insights appear within 10 seconds
✅ All 4 sections display correctly: Summary, Sentiment, Actions, Red Flags
✅ Regenerate button updates insights
✅ Cached insights load instantly on subsequent views
✅ Export button downloads insights in readable format
✅ No API key exposure or security vulnerabilities
✅ RLS policies enforce user data isolation
✅ System is simple, fast, and reliable

🚀 Next Steps After Completion

Milestone 6: Embeddings & Semantic Search
- Generate embeddings for transcripts and insights
- Implement vector storage in pgvector
- Build semantic search UI
- Enable "Find similar calls" functionality

Future Enhancements (Later):
- Batch insights generation for multiple calls
- Cost tracking dashboard (if needed later)
- User feedback on insight quality
- Custom insight templates
- Additional insight types (topics, entities, compliance scoring)

🔧 OpenAI GPT-4o Details

Model: gpt-4o (Latest GPT-4o model)
Context Window: 128,000 tokens (plenty for any call)
Output Tokens: Limit to 800 tokens (sufficient for 4 insights)
Temperature: 0.3 (balanced between creativity and consistency)
Response Format: JSON mode for structured output
Function Calling: Optional, use for guaranteed structure

Sample API Call:
```typescript
const completion = await openai.chat.completions.create({
  model: "gpt-4o",
  messages: [
    {
      role: "system",
      content: "You are an AI assistant that analyzes dental call transcripts..."
    },
    {
      role: "user",
      content: `Analyze this call transcript and provide insights:\n\n${transcript}`
    }
  ],
  response_format: { type: "json_object" },
  temperature: 0.3,
  max_tokens: 800
});
```

Error Handling:
- Call too short: Return "Too short for insights" without API call
- Rate limits: Exponential backoff with max 3 retries
- API errors: Return cached insights if available, else show error
- Token limits: Truncate transcript if too long (rare with 128K context)
- Timeouts: Set 30-second timeout, retry once

Prompt Engineering:
- Clear, concise system prompt
- Structured output instructions
- Examples for consistency (optional)
- Emphasis on actionable insights
- Request specific JSON format

Be explicit in your response: Show file tree and contents, include commands the developer must run locally, provide a brief checklist for verifying the insights system works.

Finish by creating a git commit message suggestion and recommended branch name milestone/05-ai-insights.

Keep the response machine-readable: for every file include a header with the file path (```path/to/file```) followed by content.
